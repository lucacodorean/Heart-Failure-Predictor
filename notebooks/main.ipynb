{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfedae6",
   "metadata": {},
   "source": [
    "# **Global Music Streaming Trends**\n",
    "Luca-Andrei Codorean, 30233-1 CTI-RO @2025\n",
    "\n",
    "This projects consists of an implementation of a text classifer that wishes to succesfully predict cases of heart failure.\n",
    "The used dataset can be found at: https://www.kaggle.com/datasets/atharvasoundankar/global-music-streaming-trends-and-listener-insights\n",
    "\n",
    "In order to proceed with the solution, the dependencies found in ``requirements.txt`` should be installed, using the following command ```pip install -r requirements.\n",
    "txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd937ee1",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The really first step is realted to data-preprocessing and visualization. The first function will just take one of the three datasets obtained after ```scr/data_loader.py``` script has been run.\n",
    "The ```data_loader``` script splitted the dataset in three datasets as follows: train, test, and val. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4fd71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "def preprocess_data(dataset_path: str):\n",
    "    dataset_df = pd.read_csv(dataset_path)\n",
    "\n",
    "    scaler  = MinMaxScaler()\n",
    "    le_dict = {}\n",
    "\n",
    "    for column in dataset_df.select_dtypes(include=[\"object\"]).columns:\n",
    "        le = LabelEncoder() \n",
    "        dataset_df[column] = le.fit_transform(dataset_df[column])  \n",
    "        le_dict[column] = le  \n",
    "\n",
    "    y = dataset_df[\"Listening Time (Morning/Afternoon/Night)\"]\n",
    "    X = dataset_df.drop(columns=[\"Listening Time (Morning/Afternoon/Night)\"])\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    \n",
    "    return X_scaled_df, y, le_dict, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633faa3",
   "metadata": {},
   "source": [
    "## Plotting the histograms and class distribution\n",
    "\n",
    "An issue reagrading plotting the histograms has been identified. In the early stages of the development, the columns containing strings instead of numbers were unable to be plotted as histograms. For that, they were plotted as class distribution diagrams, firstly bars, then pie charts. \n",
    "\n",
    "It's been a problem with understanding the meaning of these columns so they were mapped accordingly. See ```preprocess_data``` function.\n",
    "\n",
    "Basically, the histograms are used for numerical columns whereas the class distribution diagrams are used for the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1421f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_visualization(X, le_dict, scaler, output_dir: str):\n",
    "\n",
    "\n",
    "    temp = scaler.inverse_transform(X)\n",
    "    df = pd.DataFrame(temp, columns=X.columns)\n",
    "\n",
    "    \n",
    "    for key  in le_dict:\n",
    "        if key in df.columns:\n",
    "            label_encoder = le_dict[key]\n",
    "            df[key] = label_encoder.inverse_transform(df[key].astype(int))\n",
    "\n",
    "        \n",
    "    for column in df.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            plt.title(f\"Histogram of {column}\")\n",
    "            plt.xlabel(column)\n",
    "            df[column].plot(kind='hist', bins=30, color='skyblue', edgecolor='black')\n",
    "            plt.ylabel(\"Frequency\")\n",
    "        else:\n",
    "            plt.title(f\"Class distribution of {column}\")\n",
    "            category_counts = df[column].value_counts()\n",
    "            category_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "            plt.ylabel(\"\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir+\"/\"}{column}.png\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5790652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_formatted_file_path = \"/home/luca/SI/Project/data/preprocessed/\"\n",
    "\n",
    "train_dataset_path = \"/home/luca/SI/Project/data/raw/train.csv\"\n",
    "dataset_formatted_file_name = \"train.csv\"\n",
    "\n",
    "validation_dataset_path = \"/home/luca/SI/Project/data/raw/val.csv\"\n",
    "val_formtted_file_name = \"val.csv\"\n",
    "\n",
    "test_dataset_path = \"/home/luca/SI/Project/data/raw/test.csv\"\n",
    "test_formtted_file_name = \"test.csv\"\n",
    "\n",
    "(X, y, le_dict, scaler) = preprocess_data(dataset_path=train_dataset_path)\n",
    "(X_val, y_val, _, _)    = preprocess_data(dataset_path=validation_dataset_path)  \n",
    "(X_test, y_test, _, _)  = preprocess_data(dataset_path=test_dataset_path)\n",
    "\n",
    "# plot_visualization(X=X, le_dict=le_dict, scaler=scaler, output_dir=\"/home/luca/SI/Project/outputs/data_vizualization\")\n",
    "X.to_csv(os.path.join(dataset_formatted_file_path, dataset_formatted_file_name), index=False)\n",
    "X_val.to_csv(os.path.join(dataset_formatted_file_path, val_formtted_file_name), index=False)\n",
    "X_test.to_csv(os.path.join(dataset_formatted_file_path, test_formtted_file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e9e8a",
   "metadata": {},
   "source": [
    "## Constructing the model and the training process\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed17f0",
   "metadata": {},
   "source": [
    "### Training using a custom neuronal network\n",
    "\n",
    "After the data has been pre-processed, the very first step is to combine the output of the pre-processing phase into a ```StreamingPreferencesDataset``` object. This way, we will be able to structure a MLNN easier. For this, the ```StreamingPreferencesDatasetMLP``` class has been created. It's implementation can be found in ```src.data_set.py```.\n",
    "\n",
    "Once the dataset object is set-up, it's attributes can be used to inialized the ```HeartFailureMLP``` object that is responsible to implement the training model. Its implementation is available in ```src.model.py```. \n",
    "\n",
    "An important hyperparameter for the training process is the ```batch_size``` used by the dataloader. The model should be tested using multiple values for the ```BATCH_SIZE``` parameter in order to get the best results. Same goes for the ```LEARNINIG_RATE``` parameter.\n",
    "\n",
    "```EPOCHS``` parameter denotes the number of times the algorithm goes through the dataset.\n",
    "\n",
    "Thus, the first code fragment will handle initalization of diferent hyperparameters and of the model.\n",
    "Another analisys will be done in order to observe model's reaction to different optimizers such as Adams, SDG, SDG with momentum.\n",
    "The ```scheduler``` is used to provide the model with an already-implemented learning-rate scheduler. Its purpose is to reduce LR's value in order to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f4fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics            import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.tensorboard    import SummaryWriter\n",
    "\n",
    "def compute_metrics(writer, all_preds, all_labels, phase, epoch):\n",
    "    acc  = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds,   average='macro', zero_division=0)\n",
    "    rec  = recall_score(all_labels, all_preds,      average='macro', zero_division=0)\n",
    "    f1   = f1_score(all_labels, all_preds,          average='macro', zero_division=0)\n",
    "\n",
    "    writer.add_scalar(f\"{phase}/Accuracy\", acc, epoch)\n",
    "    writer.add_scalar(f\"{phase}/Precision\", prec, epoch)\n",
    "    writer.add_scalar(f\"{phase}/Recall\", rec, epoch)\n",
    "    writer.add_scalar(f\"{phase}/F1-Score\", f1, epoch)\n",
    "\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57988a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamingPreferencesDatasetMLP(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=16, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data   import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from src.data_set       import StreamingPreferencesDataset\n",
    "from src.model          import StreamingPreferencesDatasetMLP\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    " \n",
    "BATCH_SIZE                  = 64\n",
    "DROPOUT_PERCENTAGE          = 0.2\n",
    "LEARNING_RATE               = 1e-2\n",
    "OPTIMIZER_STEP_SIZE         = 70\n",
    "EARLY_STOPPING_PATIENCE     = 1000\n",
    "EPOCHS                      = 300\n",
    "DEVICE                      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "train_dataset   = StreamingPreferencesDataset(X, y)\n",
    "val_dataset     = StreamingPreferencesDataset(X_val, y_val)\n",
    "train_loader    = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader      = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"runs/temp\")\n",
    "\n",
    "\n",
    "all_labels = [int(label) for _, label in train_dataset]\n",
    "classes = np.unique(all_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=all_labels\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "\n",
    "model           = StreamingPreferencesDatasetMLP(dropout_percentage=DROPOUT_PERCENTAGE).to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "criterion       = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.3)  \n",
    "optimizer       = optim.SGD(model.parameters(), lr=LEARNING_RATE) #momentum=0.9, \n",
    "# optimizer     = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "# optimizer       = optim.RMSprop(model.parameters(), lr=LEARNING_RATE, alpha=0.9, eps=1e-8)\n",
    "\n",
    "scheduler      = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.7, patience=10, threshold_mode='rel',threshold=1e-4)\n",
    "# scheduler     = optim.lr_scheduler.StepLR(step_size=OPTIMIZER_STEP_SIZE, optimizer=optimizer, gamma=0.4)\n",
    "# scheduler       = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c62ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def log_confusion_matrix_tensorboard(y_true, y_pred, label_map, writer, global_step):\n",
    " \n",
    "   \n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "\n",
    " \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = [label_map[i] for i in range(len(label_map))]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(\n",
    "        xticks=np.arange(cm.shape[1]),\n",
    "        yticks=np.arange(cm.shape[0]),\n",
    "        xticklabels=classes,\n",
    "        yticklabels=classes,\n",
    "        ylabel='True label',\n",
    "        xlabel='Predicted label',\n",
    "        title='Confusion Matrix'\n",
    "    )\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    writer.add_figure(\"Confusion Matrix\", fig, global_step)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa3f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, writer):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        running_loss, total = 0.0, 0\n",
    "        train_preds, train_labels = [], []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)  \n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        compute_metrics(writer, train_preds, train_labels, \"train\", epoch)\n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss, val_total = 0.0, 0\n",
    "        val_preds, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)  \n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_epoch_loss = val_loss / val_total\n",
    "        compute_metrics(writer, val_preds, val_labels, \"val\", epoch)\n",
    "\n",
    "        scheduler.step(val_epoch_loss)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        writer.add_scalar('LearningRate', current_lr, epoch)\n",
    "        writer.add_scalar('Loss/val', val_epoch_loss, epoch)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Training Loss: {epoch_loss:.4f} Validation Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "# train_model(model, train_loader, val_loader, criterion=criterion, optimizer=optimizer, scheduler=scheduler, epochs=EPOCHS, writer=writer)\n",
    "# torch.save(model.state_dict(), \"./models/codiax_model_final.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5a3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "\n",
    "def log_confusion_matrix_tensorboard(y_true, y_pred, label_map, writer, global_step=0):\n",
    "    num_classes = len(label_map)\n",
    "    print(num_classes)\n",
    "\n",
    "    cm_metric = MulticlassConfusionMatrix(num_classes=3)\n",
    "    confmat = cm_metric(y_pred, y_true)  \n",
    "\n",
    "\n",
    "    confmat = confmat.cpu().numpy()\n",
    "    labels = list(label_map.values())\n",
    "    df_cm = pd.DataFrame(confmat, index=labels, columns=labels)\n",
    "\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    \n",
    "    writer.add_figure(\"ConfusionMatrix\", fig, global_step=global_step)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10200360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def evaluate_model(model, dataset, batch_size, device, label_map, y_true=None):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.append(preds.cpu())\n",
    "    \n",
    "    final_preds = torch.cat(all_preds)\n",
    "    final_preds_np = final_preds.numpy()\n",
    "\n",
    "\n",
    "    decoded_preds = [label_map[int(p)] for p in final_preds_np]\n",
    "    label_counts = Counter(decoded_preds)\n",
    "    total = sum(label_counts.values())\n",
    "    label_percentages = {label: (count / total) * 100 for label, count in label_counts.items()}\n",
    "\n",
    "    df_percentages = pd.DataFrame({\n",
    "        'Label': list(label_percentages.keys()),\n",
    "        'Percentage': list(label_percentages.values())\n",
    "    }).sort_values(by='Label')\n",
    "\n",
    "    accuracy = None\n",
    "    if y_true is not None:\n",
    "        y_true_np = y_true.cpu().numpy() if torch.is_tensor(y_true) else y_true\n",
    "        accuracy = accuracy_score(y_true_np, final_preds_np)\n",
    "\n",
    "    return df_percentages, accuracy, final_preds_np, final_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc85f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3490\n",
      "3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Encountered different devices in metric calculation (see stacktrace for details). This could be due to the metric class not being on the same device as input. Instead of `metric=MulticlassConfusionMatrix(...)` try to do `metric=MulticlassConfusionMatrix(...).to(device)` where device corresponds to the device of the input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SI/Project/venv/lib/python3.12/site-packages/torchmetrics/metric.py:549\u001b[39m, in \u001b[36mMetric._wrap_update.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SI/Project/venv/lib/python3.12/site-packages/torchmetrics/classification/confusion_matrix.py:285\u001b[39m, in \u001b[36mMulticlassConfusionMatrix.update\u001b[39m\u001b[34m(self, preds, target)\u001b[39m\n\u001b[32m    284\u001b[39m preds, target = _multiclass_confusion_matrix_format(preds, target, \u001b[38;5;28mself\u001b[39m.ignore_index)\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m confmat = \u001b[43m_multiclass_confusion_matrix_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[38;5;28mself\u001b[39m.confmat += confmat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SI/Project/venv/lib/python3.12/site-packages/torchmetrics/functional/classification/confusion_matrix.py:326\u001b[39m, in \u001b[36m_multiclass_confusion_matrix_update\u001b[39m\u001b[34m(preds, target, num_classes)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the bins to update the confusion matrix with.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m unique_mapping = \u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m bins = _bincount(unique_mapping, minlength=num_classes**\u001b[32m2\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m y_pred_np = final_preds.cpu().numpy() \u001b[38;5;28;01mif\u001b[39;00m torch.is_tensor(final_preds) \u001b[38;5;28;01melse\u001b[39;00m final_preds\n\u001b[32m     15\u001b[39m y_pred_tensor = torch.tensor(y_pred_np, dtype=torch.long)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mlog_confusion_matrix_tensorboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_true_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_pred_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mlog_confusion_matrix_tensorboard\u001b[39m\u001b[34m(y_true, y_pred, label_map, writer, global_step)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(num_classes)\n\u001b[32m     10\u001b[39m cm_metric = MulticlassConfusionMatrix(num_classes=\u001b[32m3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m confmat = \u001b[43mcm_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m     14\u001b[39m confmat = confmat.cpu().numpy()\n\u001b[32m     15\u001b[39m labels = \u001b[38;5;28mlist\u001b[39m(label_map.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SI/Project/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SI/Project/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SI/Project/venv/lib/python3.12/site-packages/torchmetrics/metric.py:315\u001b[39m, in \u001b[36mMetric.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28mself\u001b[39m._forward_cache = \u001b[38;5;28mself\u001b[39m._forward_full_state_update(*args, **kwargs)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28mself\u001b[39m._forward_cache = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_cache\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SI/Project/venv/lib/python3.12/site-packages/torchmetrics/metric.py:384\u001b[39m, in \u001b[36mMetric._forward_reduce_state_update\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;28mself\u001b[39m._enable_grad = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m batch_val = \u001b[38;5;28mself\u001b[39m.compute()\n\u001b[32m    387\u001b[39m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SI/Project/venv/lib/python3.12/site-packages/torchmetrics/metric.py:552\u001b[39m, in \u001b[36mMetric._wrap_update.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    551\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected all tensors to be on\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    553\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    554\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    555\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Instead of `metric=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(...)` try to do\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    556\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m `metric=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(...).to(device)` where\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    557\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m device corresponds to the device of the input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    559\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_on_cpu:\n",
      "\u001b[31mRuntimeError\u001b[39m: Encountered different devices in metric calculation (see stacktrace for details). This could be due to the metric class not being on the same device as input. Instead of `metric=MulticlassConfusionMatrix(...)` try to do `metric=MulticlassConfusionMatrix(...).to(device)` where device corresponds to the device of the input."
     ]
    }
   ],
   "source": [
    "label_map = {0: \"Morning\", 1: \"Afternoon\", 2: \"Night\"}\n",
    "\n",
    "test_dataset   = StreamingPreferencesDataset(X_test, y_test)\n",
    "                                                                 \n",
    "df_percentages, acc, final_preds_np, final_preds = evaluate_model(model, test_dataset, BATCH_SIZE, DEVICE, label_map, y_true=y_test)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "all_labels = []\n",
    "loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "for _, labels in loader:\n",
    "    all_labels.append(labels)\n",
    "y_true_tensor = torch.cat(all_labels).to(DEVICE) \n",
    "\n",
    "y_pred_np = final_preds.cpu().numpy() if torch.is_tensor(final_preds) else final_preds\n",
    "y_pred_tensor = torch.tensor(y_pred_np, dtype=torch.long)\n",
    "\n",
    "log_confusion_matrix_tensorboard(y_true=y_true_tensor, y_pred=y_pred_tensor, label_map=label_map, writer=writer, global_step=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16719f8b",
   "metadata": {},
   "source": [
    "### Training using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e03d63",
   "metadata": {},
   "source": [
    "Logistic Regression is a classic method of classification in machine learning. The difference between Logistic Regression and Liniar Regression is the capability of predicting continous outcomes. For multi-class clasification such as this one, Logistic Regression uses the softmax function. In this training process ```CrossEntropyLoss``` will be used as criterion. This removes the need of the explicity softmax layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a33f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.logistic_regression import LogisticRegression\n",
    "\n",
    "model           = LogisticRegression().to(DEVICE)\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "criterion      = nn.CrossEntropyLoss(label_smoothing=0.1)  \n",
    "# optimizer      = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer     = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler      = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.7, patience=10, threshold_mode='rel',threshold=1e-4)\n",
    "\n",
    "logisticWriter = SummaryWriter(log_dir=\"runs/temp2\")\n",
    "\n",
    "\n",
    "train_model(model=model, train_loader=train_loader, val_loader=val_loader, criterion=criterion, optimizer=optimizer, scheduler=scheduler, epochs=EPOCHS, writer=logisticWriter)\n",
    "torch.save(model.state_dict(), \"./models/logistic_model_final.pth\")\n",
    "\n",
    "df_percentages, acc, final_preds_np, final_preds = evaluate_model(model, test_dataset, BATCH_SIZE, DEVICE, label_map, y_true=y_test)\n",
    "print(df_percentages)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "all_labels = []\n",
    "loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "for _, labels in loader:\n",
    "    all_labels.append(labels)\n",
    "y_true_tensor = torch.cat(all_labels).to(DEVICE) \n",
    "\n",
    "y_pred_np = final_preds.cpu().numpy() if torch.is_tensor(final_preds) else final_preds\n",
    "y_pred_tensor = torch.tensor(y_pred_np, dtype=torch.long)\n",
    "\n",
    "log_confusion_matrix_tensorboard(y_true=y_true_tensor, y_pred=y_pred_tensor, label_map=label_map, writer=logisticWriter, global_step=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d4d45d",
   "metadata": {},
   "source": [
    "### Ensemble methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurate»õe ensemble: 0.3490\n"
     ]
    }
   ],
   "source": [
    "from src.bagging_ensemble import BaggingEnsemble\n",
    "from src.logistic_regression import LogisticRegression\n",
    "\n",
    "X_train_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "X_test_tensor  = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "logisticRegressionEnsemble = BaggingEnsemble(\n",
    "    base_model_class=LogisticRegression,\n",
    "    n_models=100,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "logisticEnsambleWriter = SummaryWriter(\"runs/logistic_ensamble\")\n",
    "\n",
    "logisticRegressionEnsamble.fit(X_train_tensor, y_train_tensor, logisticEnsambleWriter)\n",
    "y_pred = logisticRegressionEnsamble.predict(X_test_tensor)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {acc:.4f}\")\n",
    "\n",
    "MLPEnsemble = BaggingEnsemble(\n",
    "    base_model_class=StreamingPreferencesDatasetMLP,\n",
    "    n_models=100,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "logisticEnsambleWriter = SummaryWriter(\"runs/logistic_ensamble\")\n",
    "\n",
    "logisticRegressionEnsamble.fit(X_train_tensor, y_train_tensor, logisticEnsambleWriter)\n",
    "y_pred = logisticRegressionEnsamble.predict(X_test_tensor)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Heart Project)",
   "language": "python",
   "name": "heart-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
